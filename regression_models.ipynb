{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "pd.set_option('max_rows', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = pd.read_csv('twitter_accounts_complete.csv')\n",
    "updated_dict = json.load(open('cleaned_account_info.json')) \n",
    "follower = json.load(open('cleaned_follower.json'))\n",
    "following = json.load(open('cleaned_following.json'))\n",
    "twitter_types = json.load(open(\"account_type.json\"))\n",
    "experts_dict = dict(zip(experts['twitter'], experts['institution']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['house115', 'senate115', 'sen116', 'rep116', 'news_outlet', 'government_agency', 'congress'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = ['house115', 'senate115', 'sen116', 'rep116']\n",
    "twitter_types['congress'] = [j for i in twitter_types for j in twitter_types[i] if i in lst]\n",
    "twitter_types.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate components of followers/ following accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_followers(user, tar):\n",
    "    if user not in follower: return 0\n",
    "    fol = follower[user]\n",
    "    return len(set(twitter_types[tar]) & set(fol))\n",
    "\n",
    "def num_following(user, tar):\n",
    "    if user not in following: return 0\n",
    "    fol = following[user]\n",
    "    return len(set(twitter_types[tar]) & set(fol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = experts[['name', 'twitter', 'institution', \n",
    "                   'true_followers', 'true_following',\n",
    "                   'position', 'num_citation']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts['gov_followers'] = experts['twitter'].apply(lambda x: num_followers(x, 'government_agency'))\n",
    "experts['congress_followers'] = experts['twitter'].apply(lambda x: num_followers(x, 'congress'))\n",
    "experts['news_followers'] = experts['twitter'].apply(lambda x: num_followers(x, 'news_outlet'))\n",
    "experts['gov_following'] = experts['twitter'].apply(lambda x: num_following(x, 'government_agency'))\n",
    "experts['congress_following'] = experts['twitter'].apply(lambda x: num_following(x, 'congress'))\n",
    "experts['news_following'] = experts['twitter'].apply(lambda x: num_following(x, 'news_outlet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct networks to calculate centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, attrs = nx.DiGraph(), dict()\n",
    "for user in updated_dict:\n",
    "    G.add_node(user)\n",
    "    attrs[user] = dict()\n",
    "    if user in experts_dict: user_class = experts_dict[user]\n",
    "    else: \n",
    "        try: user_class = updated_dict[user]['type']\n",
    "        except TypeError: continue\n",
    "    attrs[user]['class'] = user_class\n",
    "    attrs[user]['follower'] = updated_dict[user]['follower']\n",
    "    attrs[user]['following'] = updated_dict[user]['following']\n",
    "nx.set_node_attributes(G, attrs)\n",
    "\n",
    "for user in follower:\n",
    "    for from_node in follower[user]:\n",
    "        G.add_edge(from_node, user)\n",
    "for user in following:\n",
    "    for to_node in following[user]:\n",
    "        G.add_edge(user, to_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts['inner_betweeness'] = -1\n",
    "\n",
    "for tag in ['heritage', 'brookings', 'aei']:\n",
    "    labels = nx.get_node_attributes(G, 'class') \n",
    "    tar_twitters = list(experts[experts['institution']==tag]['twitter'])\n",
    "    tar_labels = {i:labels[i] for i in labels if (labels[i] ==tag) and (i in tar_twitters)}\n",
    "    H = G.subgraph(tar_labels).copy()\n",
    "    bet_cent = nx.betweenness_centrality(H)\n",
    "    \n",
    "    experts['inner_betweeness'] = experts[['twitter', \n",
    "                                           'inner_betweeness']].apply(lambda x: bet_cent[x[0]] \n",
    "                                            if x[0] in bet_cent else x[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts['inner_degree'] = -1\n",
    "\n",
    "for tag in ['heritage', 'brookings', 'aei']:\n",
    "    labels = nx.get_node_attributes(G, 'class') \n",
    "    tar_twitters = list(experts[experts['institution']==tag]['twitter'])\n",
    "    tar_labels = {i:labels[i] for i in labels if (labels[i] ==tag) and (i in tar_twitters)}\n",
    "    H = G.subgraph(tar_labels).copy()\n",
    "    bet_cent = nx.in_degree_centrality(H)\n",
    "    \n",
    "    experts['inner_degree'] = experts[['twitter', 'inner_degree']].apply(lambda x: \n",
    "                                                                       bet_cent[x[0]] if x[0] in bet_cent else x[1], \n",
    "                                                                       axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_codes = {\n",
    "    'leadership': 4,\n",
    "    'senior fellow': 3,\n",
    "    'Resident Scholar':2,\n",
    "    \"research fellow\": 2,\n",
    "    'research Fellow':2,\n",
    "    'visiting fellow': 1,\n",
    "    'Visiting Fellow/Scholar':1,\n",
    "    'visiting Fellow/Scholar':1,\n",
    "    'nonresident fellow': 1,\n",
    "    'assistant': 0,\n",
    "    'former fellow': -1,\n",
    "    'unclear':-1,\n",
    "    np.NAN: -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts['position'] = experts['position'].apply(lambda x: position_codes[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Tweeting Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = json.load(open('expert_tweets.json'))\n",
    "#prev_months = ['Jan', 'Feb', 'Mar', 'Apr', 'May']\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', \n",
    "          'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "month_dict = dict(zip(months, range(1, 13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Twitter does not report the year of tweets so we need to \n",
    "## manually calculate it based on the change of months\n",
    "\n",
    "tweet_freq = dict()\n",
    "for key in tweets:\n",
    "    texts = tweets[key]\n",
    "    if len(texts) < 1: continue\n",
    "    print(key, '   ', end = '\\r')\n",
    "    num_original = sum(['[Original]' in i[0] for i in texts])\n",
    "    num_retweeted = sum(['[Retweeted]' in i[0] for i in texts])\n",
    "    \n",
    "    month = [i[1].split(' ')[0] for i in texts]\n",
    "    month = np.array([month_dict[i] for i in month if i in month_dict])\n",
    "    diff = month[1:] - month[:-1]\n",
    "    final_year = 2020-(sum(diff>3))\n",
    "    \n",
    "    date = texts[-1][1]\n",
    "    if len(date.split(' ')) == 3:\n",
    "        date = datetime.strptime(date, '%d %b %y')\n",
    "    else:\n",
    "        date = datetime.strptime(date + \" \"+ str(final_year), '%b %d %Y')\n",
    "        \n",
    "    length = (datetime.now() - date).days\n",
    "    tweet_freq[key] = (num_original/length, len(texts)/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts['freq_original'] = experts['twitter'].apply(lambda x: tweet_freq[x][0] if x in tweet_freq else -1)\n",
    "experts['freq_total'] = experts['twitter'].apply(lambda x: tweet_freq[x][1] if x in tweet_freq else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_experts = experts.dropna()\n",
    "cut_experts = cut_experts[cut_experts['twitter'] != '-1']\n",
    "cut_experts = cut_experts[cut_experts['inner_betweeness'] != -1]\n",
    "cut_experts = cut_experts[cut_experts['inner_degree'] != -1]\n",
    "cut_experts = cut_experts[cut_experts['position'] != -1]\n",
    "cut_experts = cut_experts[cut_experts['freq_original'] != -1]\n",
    "#cut_experts.to_csv('data_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_analysis.csv')\n",
    "sent = pd.read_csv('avg_sentiment.csv')## sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(sent, left_on = 'twitter', right_on = 'name')\n",
    "data = data[['name_x', 'twitter', 'institution', \n",
    "             'true_followers', 'true_following',\n",
    "             'gov_followers', 'congress_followers', 'news_followers', \n",
    "             'gov_following', 'congress_following', 'news_following',\n",
    "             'position', 'num_citation', 'freq_original', 'freq_total',\n",
    "             'is_neg', 'is_neu', 'is_pos', \n",
    "             'inner_betweeness', 'inner_degree']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       inner_betweeness   R-squared:                       0.314\n",
      "Model:                            OLS   Adj. R-squared:                  0.291\n",
      "Method:                 Least Squares   F-statistic:                     13.74\n",
      "Date:                Tue, 02 Jun 2020   Prob (F-statistic):           3.21e-25\n",
      "Time:                        00:32:21   Log-Likelihood:                 1235.5\n",
      "No. Observations:                 404   AIC:                            -2443.\n",
      "Df Residuals:                     390   BIC:                            -2387.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -0.0115      0.013     -0.877      0.381      -0.037       0.014\n",
      "gov_followers         -0.0002      0.000     -1.378      0.169      -0.000    8.07e-05\n",
      "congress_followers     0.0007      0.000      3.788      0.000       0.000       0.001\n",
      "news_followers        -0.0002      0.000     -1.274      0.204      -0.000       0.000\n",
      "gov_following          0.0002   5.48e-05      2.911      0.004    5.18e-05       0.000\n",
      "congress_following  1.911e-05   3.82e-05      0.501      0.617   -5.59e-05    9.41e-05\n",
      "news_following      5.896e-05   3.36e-05      1.753      0.080   -7.16e-06       0.000\n",
      "position               0.0029      0.000      5.836      0.000       0.002       0.004\n",
      "num_citation       -2.779e-08   1.29e-07     -0.216      0.829   -2.81e-07    2.25e-07\n",
      "freq_original          0.0005      0.000      1.543      0.124      -0.000       0.001\n",
      "freq_total          9.332e-05      0.000      0.448      0.654      -0.000       0.001\n",
      "is_neg                -0.0115      0.442     -0.026      0.979      -0.880       0.857\n",
      "is_neu                 0.0082      0.014      0.588      0.557      -0.019       0.035\n",
      "is_pos                -0.0279      0.060     -0.468      0.640      -0.145       0.089\n",
      "==============================================================================\n",
      "Omnibus:                      341.081   Durbin-Watson:                   1.914\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7657.804\n",
      "Skew:                           3.510   Prob(JB):                         0.00\n",
      "Kurtosis:                      23.141   Cond. No.                     3.59e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.59e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "lst = ['name_x', 'twitter', 'institution', \n",
    "       'true_followers', 'true_following',\n",
    "       'inner_degree', 'inner_betweeness']\n",
    "X = data.drop(lst, axis=1)\n",
    "y = data['inner_betweeness']\n",
    "#y = data['position']\n",
    "model = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       inner_betweeness   R-squared:                       0.725\n",
      "Model:                            OLS   Adj. R-squared:                  0.673\n",
      "Method:                 Least Squares   F-statistic:                     13.96\n",
      "Date:                Wed, 03 Jun 2020   Prob (F-statistic):           1.41e-14\n",
      "Time:                        21:19:59   Log-Likelihood:                 290.69\n",
      "No. Observations:                  83   AIC:                            -553.4\n",
      "Df Residuals:                      69   BIC:                            -519.5\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -0.0040      0.014     -0.290      0.773      -0.031       0.024\n",
      "gov_followers       8.987e-05      0.001      0.159      0.874      -0.001       0.001\n",
      "congress_followers     0.0003      0.000      1.168      0.247      -0.000       0.001\n",
      "news_followers        -0.0004      0.000     -0.839      0.404      -0.001       0.000\n",
      "gov_following      -4.529e-05   9.64e-05     -0.470      0.640      -0.000       0.000\n",
      "congress_following     0.0005      0.000      4.514      0.000       0.000       0.001\n",
      "news_following      3.093e-06   6.15e-05      0.050      0.960      -0.000       0.000\n",
      "position               0.0005      0.001      0.623      0.535      -0.001       0.002\n",
      "num_citation       -4.844e-09   2.54e-07     -0.019      0.985   -5.12e-07    5.02e-07\n",
      "freq_original          0.0039      0.002      2.216      0.030       0.000       0.007\n",
      "freq_total            -0.0007      0.001     -0.901      0.371      -0.002       0.001\n",
      "is_neg                -0.1899      0.464     -0.409      0.683      -1.115       0.736\n",
      "is_neu                 0.0023      0.015      0.152      0.880      -0.028       0.032\n",
      "is_pos                -0.0463      0.078     -0.592      0.556      -0.202       0.110\n",
      "==============================================================================\n",
      "Omnibus:                       36.872   Durbin-Watson:                   2.197\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              104.139\n",
      "Skew:                           1.457   Prob(JB):                     2.43e-23\n",
      "Kurtosis:                       7.650   Cond. No.                     1.92e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.92e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "tar = data[data['institution']=='heritage']\n",
    "X = tar.drop(lst, axis=1)\n",
    "y = tar['inner_betweeness']\n",
    "model = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
